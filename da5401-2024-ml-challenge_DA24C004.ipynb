{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:13:00.003875Z",
     "iopub.status.busy": "2024-11-05T03:13:00.002809Z",
     "iopub.status.idle": "2024-11-05T03:14:08.496973Z",
     "shell.execute_reply": "2024-11-05T03:14:08.495067Z",
     "shell.execute_reply.started": "2024-11-05T03:13:00.003817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading da5401-2024-ml-challenge.zip to /kaggle/working\n",
      "100%|█████████████████████████████████████▊| 1.05G/1.06G [00:48<00:00, 30.2MB/s]\n",
      "100%|██████████████████████████████████████| 1.06G/1.06G [00:48<00:00, 23.7MB/s]\n",
      "Archive:  da5401-2024-ml-challenge.zip\n",
      "  inflating: embeddings_1.npy        \n",
      "  inflating: embeddings_2.npy        \n",
      "  inflating: icd_codes_1.txt         \n",
      "  inflating: icd_codes_2.txt         \n",
      "  inflating: sample_solution.csv     \n",
      "  inflating: test_data.npy           \n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /root/.kaggle/\n",
    "import json\n",
    "kaggledata = {\"username\":\"aswinsda24c004\",\"key\":\"ddff2d4804059a37008296281ee668dc\"}\n",
    "kagglejson = json.dumps(kaggledata)\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(kagglejson)\n",
    "    \n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c da5401-2024-ml-challenge\n",
    "!unzip  da5401-2024-ml-challenge.zip\n",
    "!rm da5401-2024-ml-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-05T03:15:04.293868Z",
     "iopub.status.busy": "2024-11-05T03:15:04.293322Z",
     "iopub.status.idle": "2024-11-05T03:15:04.303195Z",
     "shell.execute_reply": "2024-11-05T03:15:04.301978Z",
     "shell.execute_reply.started": "2024-11-05T03:15:04.293819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel, RandomSearch, Objective\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:15:10.292377Z",
     "iopub.status.busy": "2024-11-05T03:15:10.291357Z",
     "iopub.status.idle": "2024-11-05T03:15:11.064184Z",
     "shell.execute_reply": "2024-11-05T03:15:11.062873Z",
     "shell.execute_reply.started": "2024-11-05T03:15:10.292327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings1 = np.load('embeddings_1.npy')\n",
    "embeddings2 = np.load('embeddings_2.npy')\n",
    "\n",
    "with open('icd_codes_1.txt') as f:\n",
    "    labels1 = f.read().strip().splitlines()\n",
    "\n",
    "with open('icd_codes_2.txt') as f:\n",
    "    labels2 = f.read().strip().splitlines()\n",
    "    \n",
    "X = np.concatenate((embeddings1, embeddings2), axis=0)\n",
    "y = labels1 + labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:15:13.818043Z",
     "iopub.status.busy": "2024-11-05T03:15:13.817624Z",
     "iopub.status.idle": "2024-11-05T03:17:45.362736Z",
     "shell.execute_reply": "2024-11-05T03:17:45.361619Z",
     "shell.execute_reply.started": "2024-11-05T03:15:13.818000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Multi hot encoding (OHE)\n",
    "unique_labels = sorted(set(label for entry in y for label in entry.split(';')))\n",
    "label_lookup = pd.Series(unique_labels)\n",
    "\n",
    "y_encoded = np.zeros((len(y), len(unique_labels)), dtype=int)\n",
    "for i, entry in enumerate(y):\n",
    "    for label in entry.split(';'):\n",
    "        if label in label_lookup.values:\n",
    "            y_encoded[i, label_lookup[label_lookup == label].index[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:17:50.124736Z",
     "iopub.status.busy": "2024-11-05T03:17:50.124311Z",
     "iopub.status.idle": "2024-11-05T03:17:51.160500Z",
     "shell.execute_reply": "2024-11-05T03:17:51.159392Z",
     "shell.execute_reply.started": "2024-11-05T03:17:50.124696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=np.sum(y_encoded, axis=1))\n",
    "plt.title('Distribution of Number of Labels per Sample')\n",
    "plt.xlabel('Number of Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:17:54.026782Z",
     "iopub.status.busy": "2024-11-05T03:17:54.025897Z",
     "iopub.status.idle": "2024-11-05T03:18:22.779068Z",
     "shell.execute_reply": "2024-11-05T03:18:22.777910Z",
     "shell.execute_reply.started": "2024-11-05T03:17:54.026735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Pre-processing \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:21:23.841621Z",
     "iopub.status.busy": "2024-11-05T03:21:23.841157Z",
     "iopub.status.idle": "2024-11-05T03:21:26.108229Z",
     "shell.execute_reply": "2024-11-05T03:21:26.106980Z",
     "shell.execute_reply.started": "2024-11-05T03:21:23.841579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:19:39.989016Z",
     "iopub.status.busy": "2024-11-05T03:19:39.987698Z",
     "iopub.status.idle": "2024-11-05T03:19:39.995449Z",
     "shell.execute_reply": "2024-11-05T03:19:39.994228Z",
     "shell.execute_reply.started": "2024-11-05T03:19:39.988951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f2_macro = lambda y_true, y_pred: fbeta_score(y_true, y_pred, beta=2, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:19:43.077743Z",
     "iopub.status.busy": "2024-11-05T03:19:43.077262Z",
     "iopub.status.idle": "2024-11-05T03:19:43.087403Z",
     "shell.execute_reply": "2024-11-05T03:19:43.085641Z",
     "shell.execute_reply.started": "2024-11-05T03:19:43.077697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def avg_f2_macro(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    y_true = K.cast(y_true, K.floatx())\n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f2 = (5 * precision * recall) / (4 * precision + recall + K.epsilon())\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:20:01.755939Z",
     "iopub.status.busy": "2024-11-05T03:20:01.755430Z",
     "iopub.status.idle": "2024-11-05T03:20:02.043126Z",
     "shell.execute_reply": "2024-11-05T03:20:02.041369Z",
     "shell.execute_reply.started": "2024-11-05T03:20:01.755887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, output_units):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(input_shape,)))\n",
    "    model.add(layers.Dense(1024, activation='selu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(1024, activation='selu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(output_units, activation='sigmoid'))  # Sigmoid for multi-label\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', avg_f2_macro])\n",
    "    return model\n",
    "\n",
    "mlp_model = create_model(X_train.shape[1], len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:34:47.599959Z",
     "iopub.status.busy": "2024-11-05T03:34:47.598022Z",
     "iopub.status.idle": "2024-11-05T03:34:47.611244Z",
     "shell.execute_reply": "2024-11-05T03:34:47.609669Z",
     "shell.execute_reply.started": "2024-11-05T03:34:47.599887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomLRScheduler(Callback):\n",
    "    def __init__(self, patience=3, factor=0.5, min_lr=1e-6):#changed\n",
    "        super(CustomLRScheduler, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.best_accuracy = 0\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get('accuracy') \n",
    "\n",
    "        if current_accuracy is None:\n",
    "            return\n",
    "\n",
    "\n",
    "        if current_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = current_accuracy\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
    "                tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)\n",
    "                print(f\"\\nEpoch {epoch + 1}: reducing learning rate from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "                self.wait = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T03:51:06.031086Z",
     "iopub.status.busy": "2024-11-05T03:51:06.029613Z",
     "iopub.status.idle": "2024-11-05T04:12:55.025047Z",
     "shell.execute_reply": "2024-11-05T04:12:55.023632Z",
     "shell.execute_reply.started": "2024-11-05T03:51:06.031015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5878 - avg_f2_macro: 0.3682 - loss: 0.0014\n",
      "Epoch 1: avg_f2_macro improved from -inf to 0.36635, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - accuracy: 0.5878 - avg_f2_macro: 0.3682 - loss: 0.0014 - val_accuracy: 0.5840 - val_avg_f2_macro: 0.3743 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5897 - avg_f2_macro: 0.3673 - loss: 0.0014\n",
      "Epoch 2: avg_f2_macro did not improve from 0.36635\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5897 - avg_f2_macro: 0.3673 - loss: 0.0014 - val_accuracy: 0.5848 - val_avg_f2_macro: 0.3733 - val_loss: 0.0015\n",
      "Epoch 3/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5889 - avg_f2_macro: 0.3701 - loss: 0.0014\n",
      "Epoch 3: avg_f2_macro improved from 0.36635 to 0.36841, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 147ms/step - accuracy: 0.5889 - avg_f2_macro: 0.3701 - loss: 0.0014 - val_accuracy: 0.5837 - val_avg_f2_macro: 0.3724 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5891 - avg_f2_macro: 0.3692 - loss: 0.0014\n",
      "Epoch 4: avg_f2_macro improved from 0.36841 to 0.36844, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5891 - avg_f2_macro: 0.3692 - loss: 0.0014 - val_accuracy: 0.5815 - val_avg_f2_macro: 0.3733 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5890 - avg_f2_macro: 0.3704 - loss: 0.0014\n",
      "Epoch 5: avg_f2_macro improved from 0.36844 to 0.36890, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5890 - avg_f2_macro: 0.3704 - loss: 0.0014 - val_accuracy: 0.5816 - val_avg_f2_macro: 0.3740 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5881 - avg_f2_macro: 0.3696 - loss: 0.0014\n",
      "Epoch 6: avg_f2_macro improved from 0.36890 to 0.36963, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - accuracy: 0.5881 - avg_f2_macro: 0.3696 - loss: 0.0014 - val_accuracy: 0.5816 - val_avg_f2_macro: 0.3744 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3719 - loss: 0.0014\n",
      "Epoch 7: avg_f2_macro improved from 0.36963 to 0.37028, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3719 - loss: 0.0014 - val_accuracy: 0.5872 - val_avg_f2_macro: 0.3759 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5902 - avg_f2_macro: 0.3727 - loss: 0.0014\n",
      "Epoch 8: avg_f2_macro improved from 0.37028 to 0.37184, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5902 - avg_f2_macro: 0.3727 - loss: 0.0014 - val_accuracy: 0.5850 - val_avg_f2_macro: 0.3756 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3725 - loss: 0.0014\n",
      "Epoch 9: avg_f2_macro did not improve from 0.37184\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3724 - loss: 0.0014 - val_accuracy: 0.5787 - val_avg_f2_macro: 0.3755 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5900 - avg_f2_macro: 0.3741 - loss: 0.0014\n",
      "Epoch 10: avg_f2_macro did not improve from 0.37184\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5900 - avg_f2_macro: 0.3740 - loss: 0.0014 - val_accuracy: 0.5826 - val_avg_f2_macro: 0.3748 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5867 - avg_f2_macro: 0.3747 - loss: 0.0014\n",
      "Epoch 11: avg_f2_macro improved from 0.37184 to 0.37495, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.5867 - avg_f2_macro: 0.3747 - loss: 0.0014 - val_accuracy: 0.5797 - val_avg_f2_macro: 0.3743 - val_loss: 0.0015\n",
      "Epoch 12/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5892 - avg_f2_macro: 0.3765 - loss: 0.0014\n",
      "Epoch 12: avg_f2_macro did not improve from 0.37495\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5892 - avg_f2_macro: 0.3764 - loss: 0.0014 - val_accuracy: 0.5777 - val_avg_f2_macro: 0.3749 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5904 - avg_f2_macro: 0.3757 - loss: 0.0014\n",
      "Epoch 13: avg_f2_macro did not improve from 0.37495\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - accuracy: 0.5904 - avg_f2_macro: 0.3757 - loss: 0.0014 - val_accuracy: 0.5819 - val_avg_f2_macro: 0.3756 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5926 - avg_f2_macro: 0.3769 - loss: 0.0014\n",
      "Epoch 14: avg_f2_macro improved from 0.37495 to 0.37622, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5926 - avg_f2_macro: 0.3769 - loss: 0.0014 - val_accuracy: 0.5852 - val_avg_f2_macro: 0.3762 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5922 - avg_f2_macro: 0.3793 - loss: 0.0014\n",
      "Epoch 15: avg_f2_macro improved from 0.37622 to 0.37682, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5922 - avg_f2_macro: 0.3793 - loss: 0.0014 - val_accuracy: 0.5827 - val_avg_f2_macro: 0.3766 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5900 - avg_f2_macro: 0.3806 - loss: 0.0014\n",
      "Epoch 16: avg_f2_macro improved from 0.37682 to 0.37737, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.5900 - avg_f2_macro: 0.3805 - loss: 0.0014 - val_accuracy: 0.5868 - val_avg_f2_macro: 0.3757 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5920 - avg_f2_macro: 0.3826 - loss: 0.0014\n",
      "Epoch 17: avg_f2_macro improved from 0.37737 to 0.37765, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.5920 - avg_f2_macro: 0.3825 - loss: 0.0014 - val_accuracy: 0.5819 - val_avg_f2_macro: 0.3765 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5919 - avg_f2_macro: 0.3785 - loss: 0.0014\n",
      "Epoch 18: avg_f2_macro improved from 0.37765 to 0.37791, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5919 - avg_f2_macro: 0.3785 - loss: 0.0014 - val_accuracy: 0.5830 - val_avg_f2_macro: 0.3758 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5916 - avg_f2_macro: 0.3821 - loss: 0.0014\n",
      "Epoch 19: avg_f2_macro improved from 0.37791 to 0.37942, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.5916 - avg_f2_macro: 0.3821 - loss: 0.0014 - val_accuracy: 0.5787 - val_avg_f2_macro: 0.3782 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5869 - avg_f2_macro: 0.3816 - loss: 0.0014\n",
      "Epoch 20: avg_f2_macro improved from 0.37942 to 0.37949, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5870 - avg_f2_macro: 0.3815 - loss: 0.0014 - val_accuracy: 0.5842 - val_avg_f2_macro: 0.3771 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5876 - avg_f2_macro: 0.3831 - loss: 0.0014\n",
      "Epoch 21: avg_f2_macro improved from 0.37949 to 0.38039, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5877 - avg_f2_macro: 0.3831 - loss: 0.0014 - val_accuracy: 0.5802 - val_avg_f2_macro: 0.3760 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5904 - avg_f2_macro: 0.3803 - loss: 0.0014\n",
      "Epoch 22: avg_f2_macro did not improve from 0.38039\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5904 - avg_f2_macro: 0.3803 - loss: 0.0014 - val_accuracy: 0.5839 - val_avg_f2_macro: 0.3767 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5925 - avg_f2_macro: 0.3842 - loss: 0.0014\n",
      "Epoch 23: avg_f2_macro improved from 0.38039 to 0.38118, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.5925 - avg_f2_macro: 0.3841 - loss: 0.0014 - val_accuracy: 0.5819 - val_avg_f2_macro: 0.3769 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5890 - avg_f2_macro: 0.3827 - loss: 0.0014\n",
      "Epoch 24: avg_f2_macro did not improve from 0.38118\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5890 - avg_f2_macro: 0.3827 - loss: 0.0014 - val_accuracy: 0.5845 - val_avg_f2_macro: 0.3776 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5906 - avg_f2_macro: 0.3860 - loss: 0.0014\n",
      "Epoch 25: avg_f2_macro improved from 0.38118 to 0.38254, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5906 - avg_f2_macro: 0.3859 - loss: 0.0014 - val_accuracy: 0.5773 - val_avg_f2_macro: 0.3779 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5905 - avg_f2_macro: 0.3841 - loss: 0.0013\n",
      "Epoch 26: avg_f2_macro did not improve from 0.38254\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - accuracy: 0.5905 - avg_f2_macro: 0.3841 - loss: 0.0013 - val_accuracy: 0.5809 - val_avg_f2_macro: 0.3772 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5916 - avg_f2_macro: 0.3847 - loss: 0.0013\n",
      "Epoch 27: avg_f2_macro did not improve from 0.38254\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5916 - avg_f2_macro: 0.3847 - loss: 0.0013 - val_accuracy: 0.5826 - val_avg_f2_macro: 0.3769 - val_loss: 0.0015\n",
      "Epoch 28/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5913 - avg_f2_macro: 0.3900 - loss: 0.0013\n",
      "Epoch 28: avg_f2_macro improved from 0.38254 to 0.38396, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5913 - avg_f2_macro: 0.3899 - loss: 0.0013 - val_accuracy: 0.5790 - val_avg_f2_macro: 0.3776 - val_loss: 0.0015\n",
      "Epoch 29/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5922 - avg_f2_macro: 0.3863 - loss: 0.0013\n",
      "Epoch 29: avg_f2_macro improved from 0.38396 to 0.38441, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.5922 - avg_f2_macro: 0.3863 - loss: 0.0013 - val_accuracy: 0.5843 - val_avg_f2_macro: 0.3791 - val_loss: 0.0015\n",
      "Epoch 30/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5941 - avg_f2_macro: 0.3872 - loss: 0.0013\n",
      "Epoch 30: avg_f2_macro improved from 0.38441 to 0.38588, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5941 - avg_f2_macro: 0.3872 - loss: 0.0013 - val_accuracy: 0.5766 - val_avg_f2_macro: 0.3798 - val_loss: 0.0015\n",
      "Epoch 31/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5926 - avg_f2_macro: 0.3862 - loss: 0.0013\n",
      "Epoch 31: avg_f2_macro did not improve from 0.38588\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.5925 - avg_f2_macro: 0.3862 - loss: 0.0013 - val_accuracy: 0.5794 - val_avg_f2_macro: 0.3772 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5924 - avg_f2_macro: 0.3897 - loss: 0.0013\n",
      "Epoch 32: avg_f2_macro did not improve from 0.38588\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.5923 - avg_f2_macro: 0.3897 - loss: 0.0013 - val_accuracy: 0.5826 - val_avg_f2_macro: 0.3795 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5933 - avg_f2_macro: 0.3874 - loss: 0.0013\n",
      "Epoch 33: avg_f2_macro improved from 0.38588 to 0.38612, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.5933 - avg_f2_macro: 0.3874 - loss: 0.0013 - val_accuracy: 0.5799 - val_avg_f2_macro: 0.3778 - val_loss: 0.0015\n",
      "Epoch 34/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5936 - avg_f2_macro: 0.3877 - loss: 0.0013\n",
      "Epoch 34: avg_f2_macro did not improve from 0.38612\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5936 - avg_f2_macro: 0.3877 - loss: 0.0013 - val_accuracy: 0.5887 - val_avg_f2_macro: 0.3780 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5936 - avg_f2_macro: 0.3900 - loss: 0.0013\n",
      "Epoch 35: avg_f2_macro improved from 0.38612 to 0.38714, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5936 - avg_f2_macro: 0.3899 - loss: 0.0013 - val_accuracy: 0.5804 - val_avg_f2_macro: 0.3795 - val_loss: 0.0015\n",
      "Epoch 36/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5896 - avg_f2_macro: 0.3903 - loss: 0.0013\n",
      "Epoch 36: avg_f2_macro improved from 0.38714 to 0.38851, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5896 - avg_f2_macro: 0.3903 - loss: 0.0013 - val_accuracy: 0.5785 - val_avg_f2_macro: 0.3769 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5937 - avg_f2_macro: 0.3922 - loss: 0.0013\n",
      "Epoch 37: avg_f2_macro improved from 0.38851 to 0.38866, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 149ms/step - accuracy: 0.5937 - avg_f2_macro: 0.3922 - loss: 0.0013 - val_accuracy: 0.5830 - val_avg_f2_macro: 0.3787 - val_loss: 0.0015\n",
      "Epoch 38/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5919 - avg_f2_macro: 0.3889 - loss: 0.0013\n",
      "Epoch 38: avg_f2_macro improved from 0.38866 to 0.38944, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5919 - avg_f2_macro: 0.3889 - loss: 0.0013 - val_accuracy: 0.5817 - val_avg_f2_macro: 0.3780 - val_loss: 0.0015\n",
      "Epoch 39/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3890 - loss: 0.0013\n",
      "Epoch 39: avg_f2_macro improved from 0.38944 to 0.38970, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5910 - avg_f2_macro: 0.3890 - loss: 0.0013 - val_accuracy: 0.5839 - val_avg_f2_macro: 0.3782 - val_loss: 0.0015\n",
      "Epoch 40/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5951 - avg_f2_macro: 0.3931 - loss: 0.0013\n",
      "Epoch 40: avg_f2_macro improved from 0.38970 to 0.39006, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.5950 - avg_f2_macro: 0.3930 - loss: 0.0013 - val_accuracy: 0.5862 - val_avg_f2_macro: 0.3782 - val_loss: 0.0015\n",
      "Epoch 41/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5943 - avg_f2_macro: 0.3914 - loss: 0.0013\n",
      "Epoch 41: avg_f2_macro did not improve from 0.39006\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.5943 - avg_f2_macro: 0.3913 - loss: 0.0013 - val_accuracy: 0.5835 - val_avg_f2_macro: 0.3798 - val_loss: 0.0016\n",
      "Epoch 42/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5951 - avg_f2_macro: 0.3915 - loss: 0.0013\n",
      "Epoch 42: avg_f2_macro did not improve from 0.39006\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5951 - avg_f2_macro: 0.3915 - loss: 0.0013 - val_accuracy: 0.5803 - val_avg_f2_macro: 0.3797 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5947 - avg_f2_macro: 0.3930 - loss: 0.0013\n",
      "Epoch 43: avg_f2_macro did not improve from 0.39006\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.5947 - avg_f2_macro: 0.3930 - loss: 0.0013 - val_accuracy: 0.5773 - val_avg_f2_macro: 0.3784 - val_loss: 0.0015\n",
      "Epoch 44/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5913 - avg_f2_macro: 0.3937 - loss: 0.0013\n",
      "Epoch 44: avg_f2_macro improved from 0.39006 to 0.39085, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5913 - avg_f2_macro: 0.3936 - loss: 0.0013 - val_accuracy: 0.5813 - val_avg_f2_macro: 0.3782 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5928 - avg_f2_macro: 0.3939 - loss: 0.0013\n",
      "Epoch 45: avg_f2_macro improved from 0.39085 to 0.39239, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.5928 - avg_f2_macro: 0.3938 - loss: 0.0013 - val_accuracy: 0.5803 - val_avg_f2_macro: 0.3790 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5965 - avg_f2_macro: 0.3938 - loss: 0.0013\n",
      "Epoch 46: avg_f2_macro improved from 0.39239 to 0.39286, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5965 - avg_f2_macro: 0.3938 - loss: 0.0013 - val_accuracy: 0.5830 - val_avg_f2_macro: 0.3793 - val_loss: 0.0016\n",
      "Epoch 47/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5943 - avg_f2_macro: 0.3956 - loss: 0.0013\n",
      "Epoch 47: avg_f2_macro did not improve from 0.39286\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.5943 - avg_f2_macro: 0.3956 - loss: 0.0013 - val_accuracy: 0.5787 - val_avg_f2_macro: 0.3789 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5959 - avg_f2_macro: 0.3942 - loss: 0.0013\n",
      "Epoch 48: avg_f2_macro improved from 0.39286 to 0.39307, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5959 - avg_f2_macro: 0.3942 - loss: 0.0013 - val_accuracy: 0.5797 - val_avg_f2_macro: 0.3792 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5982 - avg_f2_macro: 0.3962 - loss: 0.0013\n",
      "Epoch 49: avg_f2_macro improved from 0.39307 to 0.39409, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5982 - avg_f2_macro: 0.3961 - loss: 0.0013 - val_accuracy: 0.5810 - val_avg_f2_macro: 0.3803 - val_loss: 0.0015\n",
      "Epoch 50/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5954 - avg_f2_macro: 0.3976 - loss: 0.0013\n",
      "Epoch 50: avg_f2_macro did not improve from 0.39409\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5954 - avg_f2_macro: 0.3976 - loss: 0.0013 - val_accuracy: 0.5863 - val_avg_f2_macro: 0.3801 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5974 - avg_f2_macro: 0.3960 - loss: 0.0013\n",
      "Epoch 51: avg_f2_macro did not improve from 0.39409\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.5974 - avg_f2_macro: 0.3959 - loss: 0.0013 - val_accuracy: 0.5861 - val_avg_f2_macro: 0.3775 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5951 - avg_f2_macro: 0.3980 - loss: 0.0013\n",
      "Epoch 52: avg_f2_macro improved from 0.39409 to 0.39437, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5951 - avg_f2_macro: 0.3979 - loss: 0.0013 - val_accuracy: 0.5858 - val_avg_f2_macro: 0.3795 - val_loss: 0.0016\n",
      "Epoch 53/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5973 - avg_f2_macro: 0.3957 - loss: 0.0013\n",
      "Epoch 53: avg_f2_macro improved from 0.39437 to 0.39490, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5972 - avg_f2_macro: 0.3957 - loss: 0.0013 - val_accuracy: 0.5869 - val_avg_f2_macro: 0.3782 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5968 - avg_f2_macro: 0.3986 - loss: 0.0013\n",
      "Epoch 54: avg_f2_macro improved from 0.39490 to 0.39504, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.5968 - avg_f2_macro: 0.3986 - loss: 0.0013 - val_accuracy: 0.5800 - val_avg_f2_macro: 0.3785 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5947 - avg_f2_macro: 0.3976 - loss: 0.0013\n",
      "Epoch 55: avg_f2_macro improved from 0.39504 to 0.39599, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - accuracy: 0.5947 - avg_f2_macro: 0.3975 - loss: 0.0013 - val_accuracy: 0.5825 - val_avg_f2_macro: 0.3790 - val_loss: 0.0016\n",
      "Epoch 56/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5933 - avg_f2_macro: 0.3978 - loss: 0.0013\n",
      "Epoch 56: avg_f2_macro did not improve from 0.39599\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5933 - avg_f2_macro: 0.3978 - loss: 0.0013 - val_accuracy: 0.5776 - val_avg_f2_macro: 0.3813 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5944 - avg_f2_macro: 0.3997 - loss: 0.0013\n",
      "Epoch 57: avg_f2_macro improved from 0.39599 to 0.39656, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5943 - avg_f2_macro: 0.3997 - loss: 0.0013 - val_accuracy: 0.5798 - val_avg_f2_macro: 0.3792 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5942 - avg_f2_macro: 0.3992 - loss: 0.0013\n",
      "Epoch 58: avg_f2_macro did not improve from 0.39656\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5942 - avg_f2_macro: 0.3992 - loss: 0.0013 - val_accuracy: 0.5785 - val_avg_f2_macro: 0.3787 - val_loss: 0.0016\n",
      "Epoch 59/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5953 - avg_f2_macro: 0.3975 - loss: 0.0013\n",
      "Epoch 59: avg_f2_macro did not improve from 0.39656\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 148ms/step - accuracy: 0.5953 - avg_f2_macro: 0.3974 - loss: 0.0013 - val_accuracy: 0.5812 - val_avg_f2_macro: 0.3803 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5998 - avg_f2_macro: 0.3994 - loss: 0.0013\n",
      "Epoch 60: avg_f2_macro did not improve from 0.39656\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5998 - avg_f2_macro: 0.3993 - loss: 0.0013 - val_accuracy: 0.5813 - val_avg_f2_macro: 0.3789 - val_loss: 0.0016\n",
      "Epoch 61/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5971 - avg_f2_macro: 0.3981 - loss: 0.0013\n",
      "Epoch 61: avg_f2_macro improved from 0.39656 to 0.39713, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - accuracy: 0.5971 - avg_f2_macro: 0.3981 - loss: 0.0013 - val_accuracy: 0.5853 - val_avg_f2_macro: 0.3802 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5954 - avg_f2_macro: 0.4012 - loss: 0.0012\n",
      "Epoch 62: avg_f2_macro improved from 0.39713 to 0.39720, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - accuracy: 0.5953 - avg_f2_macro: 0.4011 - loss: 0.0012 - val_accuracy: 0.5835 - val_avg_f2_macro: 0.3809 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5961 - avg_f2_macro: 0.3994 - loss: 0.0013\n",
      "Epoch 63: avg_f2_macro improved from 0.39720 to 0.39744, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5961 - avg_f2_macro: 0.3994 - loss: 0.0013 - val_accuracy: 0.5806 - val_avg_f2_macro: 0.3810 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5953 - avg_f2_macro: 0.3994 - loss: 0.0013\n",
      "Epoch 64: avg_f2_macro improved from 0.39744 to 0.39761, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5953 - avg_f2_macro: 0.3994 - loss: 0.0013 - val_accuracy: 0.5833 - val_avg_f2_macro: 0.3791 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5975 - avg_f2_macro: 0.4029 - loss: 0.0012\n",
      "Epoch 65: avg_f2_macro improved from 0.39761 to 0.39981, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5975 - avg_f2_macro: 0.4029 - loss: 0.0012 - val_accuracy: 0.5779 - val_avg_f2_macro: 0.3790 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5983 - avg_f2_macro: 0.3990 - loss: 0.0012\n",
      "Epoch 66: avg_f2_macro did not improve from 0.39981\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5983 - avg_f2_macro: 0.3990 - loss: 0.0012 - val_accuracy: 0.5783 - val_avg_f2_macro: 0.3802 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5954 - avg_f2_macro: 0.4001 - loss: 0.0012\n",
      "Epoch 67: avg_f2_macro did not improve from 0.39981\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - accuracy: 0.5954 - avg_f2_macro: 0.4001 - loss: 0.0012 - val_accuracy: 0.5812 - val_avg_f2_macro: 0.3793 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5974 - avg_f2_macro: 0.4012 - loss: 0.0012\n",
      "Epoch 68: avg_f2_macro improved from 0.39981 to 0.39983, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.5974 - avg_f2_macro: 0.4012 - loss: 0.0012 - val_accuracy: 0.5906 - val_avg_f2_macro: 0.3790 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5975 - avg_f2_macro: 0.4014 - loss: 0.0012\n",
      "Epoch 69: avg_f2_macro improved from 0.39983 to 0.40002, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.5975 - avg_f2_macro: 0.4014 - loss: 0.0012 - val_accuracy: 0.5830 - val_avg_f2_macro: 0.3806 - val_loss: 0.0016\n",
      "Epoch 70/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5976 - avg_f2_macro: 0.4031 - loss: 0.0012\n",
      "Epoch 70: avg_f2_macro improved from 0.40002 to 0.40168, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.5976 - avg_f2_macro: 0.4031 - loss: 0.0012 - val_accuracy: 0.5811 - val_avg_f2_macro: 0.3804 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5982 - avg_f2_macro: 0.4031 - loss: 0.0012\n",
      "Epoch 71: avg_f2_macro did not improve from 0.40168\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.5982 - avg_f2_macro: 0.4030 - loss: 0.0012 - val_accuracy: 0.5768 - val_avg_f2_macro: 0.3804 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5947 - avg_f2_macro: 0.4043 - loss: 0.0012\n",
      "Epoch 72: avg_f2_macro did not improve from 0.40168\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.5947 - avg_f2_macro: 0.4043 - loss: 0.0012 - val_accuracy: 0.5830 - val_avg_f2_macro: 0.3808 - val_loss: 0.0016\n",
      "Epoch 73/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5989 - avg_f2_macro: 0.4012 - loss: 0.0012\n",
      "Epoch 73: avg_f2_macro did not improve from 0.40168\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5989 - avg_f2_macro: 0.4012 - loss: 0.0012 - val_accuracy: 0.5789 - val_avg_f2_macro: 0.3800 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5972 - avg_f2_macro: 0.4029 - loss: 0.0012\n",
      "Epoch 74: avg_f2_macro did not improve from 0.40168\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.5972 - avg_f2_macro: 0.4029 - loss: 0.0012 - val_accuracy: 0.5785 - val_avg_f2_macro: 0.3810 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5979 - avg_f2_macro: 0.4054 - loss: 0.0012\n",
      "Epoch 75: avg_f2_macro improved from 0.40168 to 0.40221, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.5979 - avg_f2_macro: 0.4054 - loss: 0.0012 - val_accuracy: 0.5776 - val_avg_f2_macro: 0.3820 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5969 - avg_f2_macro: 0.4060 - loss: 0.0012\n",
      "Epoch 76: avg_f2_macro improved from 0.40221 to 0.40332, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 144ms/step - accuracy: 0.5969 - avg_f2_macro: 0.4059 - loss: 0.0012 - val_accuracy: 0.5799 - val_avg_f2_macro: 0.3811 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5952 - avg_f2_macro: 0.4028 - loss: 0.0012\n",
      "Epoch 77: avg_f2_macro did not improve from 0.40332\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5952 - avg_f2_macro: 0.4028 - loss: 0.0012 - val_accuracy: 0.5823 - val_avg_f2_macro: 0.3797 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5958 - avg_f2_macro: 0.4045 - loss: 0.0012\n",
      "Epoch 78: avg_f2_macro did not improve from 0.40332\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5958 - avg_f2_macro: 0.4045 - loss: 0.0012 - val_accuracy: 0.5774 - val_avg_f2_macro: 0.3805 - val_loss: 0.0016\n",
      "Epoch 79/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6014 - avg_f2_macro: 0.4060 - loss: 0.0012\n",
      "Epoch 79: avg_f2_macro improved from 0.40332 to 0.40361, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.6014 - avg_f2_macro: 0.4060 - loss: 0.0012 - val_accuracy: 0.5852 - val_avg_f2_macro: 0.3793 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5993 - avg_f2_macro: 0.4054 - loss: 0.0012\n",
      "Epoch 80: avg_f2_macro did not improve from 0.40361\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5993 - avg_f2_macro: 0.4054 - loss: 0.0012 - val_accuracy: 0.5808 - val_avg_f2_macro: 0.3803 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5997 - avg_f2_macro: 0.4055 - loss: 0.0012\n",
      "Epoch 81: avg_f2_macro did not improve from 0.40361\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5997 - avg_f2_macro: 0.4055 - loss: 0.0012 - val_accuracy: 0.5796 - val_avg_f2_macro: 0.3809 - val_loss: 0.0016\n",
      "Epoch 82/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5966 - avg_f2_macro: 0.4052 - loss: 0.0012\n",
      "Epoch 82: avg_f2_macro improved from 0.40361 to 0.40377, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 140ms/step - accuracy: 0.5966 - avg_f2_macro: 0.4052 - loss: 0.0012 - val_accuracy: 0.5823 - val_avg_f2_macro: 0.3799 - val_loss: 0.0016\n",
      "Epoch 83/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5956 - avg_f2_macro: 0.4052 - loss: 0.0012\n",
      "Epoch 83: avg_f2_macro improved from 0.40377 to 0.40386, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5957 - avg_f2_macro: 0.4052 - loss: 0.0012 - val_accuracy: 0.5814 - val_avg_f2_macro: 0.3801 - val_loss: 0.0016\n",
      "Epoch 84/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6003 - avg_f2_macro: 0.4039 - loss: 0.0012\n",
      "Epoch 84: avg_f2_macro did not improve from 0.40386\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.6003 - avg_f2_macro: 0.4039 - loss: 0.0012 - val_accuracy: 0.5819 - val_avg_f2_macro: 0.3812 - val_loss: 0.0016\n",
      "Epoch 85/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5999 - avg_f2_macro: 0.4065 - loss: 0.0012\n",
      "Epoch 85: avg_f2_macro did not improve from 0.40386\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5999 - avg_f2_macro: 0.4065 - loss: 0.0012 - val_accuracy: 0.5796 - val_avg_f2_macro: 0.3802 - val_loss: 0.0016\n",
      "Epoch 86/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5957 - avg_f2_macro: 0.4085 - loss: 0.0012\n",
      "Epoch 86: avg_f2_macro improved from 0.40386 to 0.40485, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.5957 - avg_f2_macro: 0.4084 - loss: 0.0012 - val_accuracy: 0.5858 - val_avg_f2_macro: 0.3810 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5999 - avg_f2_macro: 0.4069 - loss: 0.0012\n",
      "Epoch 87: avg_f2_macro improved from 0.40485 to 0.40490, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.5999 - avg_f2_macro: 0.4069 - loss: 0.0012 - val_accuracy: 0.5836 - val_avg_f2_macro: 0.3807 - val_loss: 0.0016\n",
      "Epoch 88/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5974 - avg_f2_macro: 0.4095 - loss: 0.0012\n",
      "Epoch 88: avg_f2_macro improved from 0.40490 to 0.40584, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.5974 - avg_f2_macro: 0.4095 - loss: 0.0012 - val_accuracy: 0.5798 - val_avg_f2_macro: 0.3814 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6006 - avg_f2_macro: 0.4104 - loss: 0.0012\n",
      "Epoch 89: avg_f2_macro improved from 0.40584 to 0.40589, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.6006 - avg_f2_macro: 0.4103 - loss: 0.0012 - val_accuracy: 0.5795 - val_avg_f2_macro: 0.3807 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5991 - avg_f2_macro: 0.4076 - loss: 0.0012\n",
      "Epoch 90: avg_f2_macro did not improve from 0.40589\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5991 - avg_f2_macro: 0.4075 - loss: 0.0012 - val_accuracy: 0.5823 - val_avg_f2_macro: 0.3800 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5987 - avg_f2_macro: 0.4106 - loss: 0.0012\n",
      "Epoch 91: avg_f2_macro improved from 0.40589 to 0.40634, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.5987 - avg_f2_macro: 0.4106 - loss: 0.0012 - val_accuracy: 0.5771 - val_avg_f2_macro: 0.3804 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5961 - avg_f2_macro: 0.4084 - loss: 0.0012\n",
      "Epoch 92: avg_f2_macro did not improve from 0.40634\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.5961 - avg_f2_macro: 0.4084 - loss: 0.0012 - val_accuracy: 0.5824 - val_avg_f2_macro: 0.3810 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5972 - avg_f2_macro: 0.4088 - loss: 0.0012\n",
      "Epoch 93: avg_f2_macro improved from 0.40634 to 0.40679, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5972 - avg_f2_macro: 0.4087 - loss: 0.0012 - val_accuracy: 0.5801 - val_avg_f2_macro: 0.3795 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5967 - avg_f2_macro: 0.4080 - loss: 0.0012\n",
      "Epoch 94: avg_f2_macro did not improve from 0.40679\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.5967 - avg_f2_macro: 0.4080 - loss: 0.0012 - val_accuracy: 0.5814 - val_avg_f2_macro: 0.3807 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5988 - avg_f2_macro: 0.4082 - loss: 0.0012\n",
      "Epoch 95: avg_f2_macro did not improve from 0.40679\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - accuracy: 0.5988 - avg_f2_macro: 0.4082 - loss: 0.0012 - val_accuracy: 0.5853 - val_avg_f2_macro: 0.3808 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6032 - avg_f2_macro: 0.4103 - loss: 0.0012\n",
      "Epoch 96: avg_f2_macro improved from 0.40679 to 0.40723, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.6032 - avg_f2_macro: 0.4103 - loss: 0.0012 - val_accuracy: 0.5845 - val_avg_f2_macro: 0.3792 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5986 - avg_f2_macro: 0.4067 - loss: 0.0012\n",
      "Epoch 97: avg_f2_macro did not improve from 0.40723\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5986 - avg_f2_macro: 0.4067 - loss: 0.0012 - val_accuracy: 0.5896 - val_avg_f2_macro: 0.3810 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6027 - avg_f2_macro: 0.4095 - loss: 0.0012\n",
      "Epoch 98: avg_f2_macro did not improve from 0.40723\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.6027 - avg_f2_macro: 0.4095 - loss: 0.0012 - val_accuracy: 0.5812 - val_avg_f2_macro: 0.3808 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6003 - avg_f2_macro: 0.4115 - loss: 0.0012\n",
      "Epoch 99: avg_f2_macro improved from 0.40723 to 0.40778, saving model to best_mlp_model.keras\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 144ms/step - accuracy: 0.6003 - avg_f2_macro: 0.4115 - loss: 0.0012 - val_accuracy: 0.5813 - val_avg_f2_macro: 0.3805 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5993 - avg_f2_macro: 0.4105 - loss: 0.0012\n",
      "Epoch 100: avg_f2_macro did not improve from 0.40778\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5993 - avg_f2_macro: 0.4105 - loss: 0.0012 - val_accuracy: 0.5800 - val_avg_f2_macro: 0.3798 - val_loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_scheduler = CustomLRScheduler(patience=5, factor=0.5, min_lr=1e-6)\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    'best_mlp_model.keras',  \n",
    "    monitor='avg_f2_macro', \n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = mlp_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=2048, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T04:13:14.871060Z",
     "iopub.status.busy": "2024-11-05T04:13:14.870637Z",
     "iopub.status.idle": "2024-11-05T04:13:29.619463Z",
     "shell.execute_reply": "2024-11-05T04:13:29.618313Z",
     "shell.execute_reply.started": "2024-11-05T04:13:14.871022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Best MLP Model Accuracy: 0.6086, F2 Score: 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "best_mlp_model = models.load_model('best_mlp_model.keras', custom_objects={'avg_f2_macro': avg_f2_macro})\n",
    "\n",
    "\n",
    "y_pred_best_mlp = best_mlp_model.predict(X_val, batch_size=2048)\n",
    "accuracy_best_mlp = accuracy_score(y_val, np.round(y_pred_best_mlp))\n",
    "f2_best_mlp = fbeta_score(y_val, np.round(y_pred_best_mlp), beta=2, average='macro')\n",
    "print(f'Best MLP Model Accuracy: {accuracy_best_mlp:.4f}, F2 Score: {f2_best_mlp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T04:13:42.153004Z",
     "iopub.status.busy": "2024-11-05T04:13:42.151684Z",
     "iopub.status.idle": "2024-11-05T04:13:53.348609Z",
     "shell.execute_reply": "2024-11-05T04:13:53.347292Z",
     "shell.execute_reply.started": "2024-11-05T04:13:42.152949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load('test_data.npy')\n",
    "\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "test_data_pca = pca.transform(test_data_scaled)\n",
    "\n",
    "y_test_pred = best_mlp_model.predict(test_data_pca, batch_size=256)\n",
    "y_test_pred_rounded = np.round(y_test_pred)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(1, len(y_test_pred) + 1), \n",
    "    'labels': [';'.join(sorted(label_lookup[y_test_pred_rounded[i] == 1])) for i in range(len(y_test_pred_rounded))]\n",
    "})\n",
    "\n",
    "submission.to_csv('submissions5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9904132,
     "sourceId": 85893,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
